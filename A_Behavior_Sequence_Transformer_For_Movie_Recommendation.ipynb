{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aUG4oG3JSGCn"
      },
      "source": [
        "# A Behavior Sequence Transformer For Movie Recommendation\n",
        "\n",
        "**Author:** [Nelson Lin](https://www.linkedin.com/in/nelson-lin-842564164/)<br>\n",
        "**Date created:** 2024/07/09<br>\n",
        "**Last modified:** 2024/07/09<br>\n",
        "**Description:** Rating rate prediction using the Behavior Sequence Transformer (BST) model on the Movielens 1M."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "10UcMwj-Sjqv"
      },
      "source": [
        "## (1) Notebook Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxoBk0OkSvPn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_RHfTP4S3IZ"
      },
      "source": [
        "## (2) Data preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm747EdZU1bZ"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrasdLSrSG1x"
      },
      "outputs": [],
      "source": [
        "urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "ZipFile(\"movielens.zip\", \"r\").extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8YFIdZeSxaH"
      },
      "outputs": [],
      "source": [
        "users = pd.read_csv(\n",
        "    \"ml-1m/users.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
        "    engine='python'\n",
        ")\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
        "    engine='python'\n",
        ")\n",
        "\n",
        "movies = pd.read_csv(\n",
        "    \"ml-1m/movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"],\n",
        "    engine='python',encoding='ISO-8859-1'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRanAvKU9t1"
      },
      "source": [
        "### Remap ID to index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxDgQLlHS17f"
      },
      "outputs": [],
      "source": [
        "# remap the id to index\n",
        "def generate_remap_id_dict(df,col):\n",
        "    ids = df[df[col].notnull()][col].unique().tolist()\n",
        "    ids = sorted(ids)\n",
        "    id_map_dict = {x: i+1 for i, x in enumerate(ids)}\n",
        "    id_map_dict[\"UNK\"]=0\n",
        "\n",
        "    df[f\"{col}_index\"] = df[col].fillna(\"UNK\").map(id_map_dict)\n",
        "\n",
        "    return id_map_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sCplGKlTHHt"
      },
      "outputs": [],
      "source": [
        "user_id_map_dict = generate_remap_id_dict(users,col='user_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jl_-Q_yYUA-6",
        "outputId": "a37170ca-c76f-4d1c-e1e8-1cdcd42e5c0a"
      },
      "outputs": [],
      "source": [
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsCN2BJ0UAQC"
      },
      "outputs": [],
      "source": [
        "# remap sex to score\n",
        "sex_id_map_dict = {'M':0.0,'F':1.0,'UNK':0.5}\n",
        "users['sex']=users['sex'].map(sex_id_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssHECS9iTZ3A"
      },
      "outputs": [],
      "source": [
        "occupation_id_map_dict = generate_remap_id_dict(users,col='occupation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGTwjedfTfN1"
      },
      "outputs": [],
      "source": [
        "age_group_id_map_dict = generate_remap_id_dict(users,col='age_group')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRtH_iAeTgn0"
      },
      "outputs": [],
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "ratings[\"norm_rating\"] = min_max_scaler.fit_transform(\n",
        "    ratings[\"rating\"].values.reshape(-1, 1))[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqur_n48Trck"
      },
      "outputs": [],
      "source": [
        "movie_id_map_dict = generate_remap_id_dict(movies,col='movie_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSu3fNkyTv6D"
      },
      "outputs": [],
      "source": [
        "genres_set = set()\n",
        "def get_genres_set(genres):\n",
        "    global genres_set\n",
        "    genres_split = genres.split(\"|\")\n",
        "    genres_set.update(genres_split)\n",
        "    return genres_split\n",
        "movies['genres'] = movies['genres'].apply(lambda x:get_genres_set(x))\n",
        "genres_map_dict ={x: i+1 for i, x in enumerate(sorted(genres_set))}\n",
        "genres_map_dict['UNK']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD5T2WuYUUuB"
      },
      "outputs": [],
      "source": [
        "movies['genres_ids']= movies['genres'].apply(lambda x: [genres_map_dict[g] for g in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbMexz0nUPyz"
      },
      "outputs": [],
      "source": [
        "ratings['movie_id_index'] = ratings['movie_id'].map(movie_id_map_dict)\n",
        "ratings['user_id_index'] = ratings['user_id'].map(user_id_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NW-x8FdTy40"
      },
      "outputs": [],
      "source": [
        "df_user_views = ratings[[\"movie_id_index\", \"user_id_index\", \"unix_timestamp\", \"norm_rating\"]] \\\n",
        "    .merge(movies[['movie_id_index', 'genres_ids']],\n",
        "           on=['movie_id_index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QM1VX4lVUMMa",
        "outputId": "aca32242-4f66-4be8-bdab-669ab38d1a26"
      },
      "outputs": [],
      "source": [
        "df_user_views.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uoGM6uUsKF"
      },
      "source": [
        "### Prepare the Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvQBp4moVNEf"
      },
      "outputs": [],
      "source": [
        "df_agg_ratings = df_user_views.sort_values(by=[\"unix_timestamp\"]).groupby(\"user_id_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44_d1f5pVSqX"
      },
      "outputs": [],
      "source": [
        "ratings_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"user_id_index\": list(df_agg_ratings.groups.keys()),\n",
        "        \"movie_sequence\": list(df_agg_ratings.movie_id_index.apply(list)),\n",
        "        \"rating_sequence\": list(df_agg_ratings.norm_rating.apply(list)),\n",
        "        \"timestamps\": list(df_agg_ratings.unix_timestamp.apply(list)),\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrruVMSyUxXW"
      },
      "outputs": [],
      "source": [
        "sequence_length = 4\n",
        "step_size = 2\n",
        "\n",
        "\n",
        "def create_sequences(values, window_size, step_size):\n",
        "    sequences = []\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        end_index = start_index + window_size\n",
        "        seq = values[start_index:end_index]\n",
        "        if len(seq) < window_size:\n",
        "            seq = values[-window_size:]\n",
        "            if len(seq) == window_size:\n",
        "                sequences.append(seq)\n",
        "            break\n",
        "        sequences.append(seq)\n",
        "        start_index += step_size\n",
        "    return sequences\n",
        "\n",
        "\n",
        "ratings_data.movie_sequence\t = ratings_data.movie_sequence.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "ratings_data.rating_sequence = ratings_data.rating_sequence.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "del ratings_data[\"timestamps\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eREuVC30VU03"
      },
      "outputs": [],
      "source": [
        "ratings_data_movies = ratings_data[[\"user_id_index\", \"movie_sequence\"]].explode(\n",
        "    \"movie_sequence\", ignore_index=True\n",
        ")\n",
        "ratings_data_rating = ratings_data[[\"rating_sequence\"]].explode(\"rating_sequence\", ignore_index=True)\n",
        "ratings_data_transformed = pd.concat([ratings_data_movies, ratings_data_rating], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K-yTVNctVWbn",
        "outputId": "d51b685b-cc56-4caf-f201-729232ee2c2f"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roXPTpv8VY-9"
      },
      "outputs": [],
      "source": [
        "user_columns = ['user_id_index',\n",
        "                'sex',\n",
        "                'occupation_index',\n",
        "                'age_group_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kotYicQYVaGe"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed = ratings_data_transformed.merge(\n",
        "    users[user_columns], on=\"user_id_index\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUE9Aj-JVbB_"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed['sex'] = ratings_data_transformed['sex'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f6yhP5ZVcPk"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed['target_movie'] =  ratings_data_transformed['movie_sequence'].apply(lambda x:x[-1])\n",
        "ratings_data_transformed['target_rating'] =  ratings_data_transformed['rating_sequence'].apply(lambda x:x[-1])\n",
        "# mask the last rating\n",
        "mask_score = 1.0\n",
        "ratings_data_transformed['rating_sequence'] =  ratings_data_transformed['rating_sequence'].apply(lambda x:x[:-1]+[mask_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_D1bExqMVkRd",
        "outputId": "c23bbf8a-0b53-47bc-fc80-82cb54374ba1"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQEmshcNVlks"
      },
      "outputs": [],
      "source": [
        "random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "train_data = ratings_data_transformed[random_selection]\n",
        "test_data = ratings_data_transformed[~random_selection]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bXqZBv7BVv4v"
      },
      "source": [
        "## (3) Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74j7Qs7LVxkF"
      },
      "outputs": [],
      "source": [
        "num_user = len(user_id_map_dict)\n",
        "num_movie = len(movie_id_map_dict)\n",
        "num_occupation = len(occupation_id_map_dict)\n",
        "num_age_group = len(age_group_id_map_dict)\n",
        "# num_genre = len(genres_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4MOe95uV2qg"
      },
      "outputs": [],
      "source": [
        "embed_configs = {}\n",
        "EMED_DIM=32\n",
        "sequence_length=4\n",
        "embed_configs['user']={\"embed_dim\":EMED_DIM,\"num_embed\":num_user}\n",
        "embed_configs['movie']={\"embed_dim\":EMED_DIM,\"num_embed\":num_movie}\n",
        "embed_configs['occupation']={\"embed_dim\":EMED_DIM,\"num_embed\":num_occupation}\n",
        "embed_configs['age_group']={\"embed_dim\":EMED_DIM,\"num_embed\":num_age_group}\n",
        "embed_configs['position'] = {\"embed_dim\":EMED_DIM,\"num_embed\":sequence_length}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p7ikk9DV_od"
      },
      "outputs": [],
      "source": [
        "config_dict={}\n",
        "config_dict['embed_configs'] = embed_configs\n",
        "config_dict['transformer_num_layer']=3\n",
        "config_dict['dropout']=0.2\n",
        "config_dict['epoches']=1\n",
        "config_dict['learning_rate']=0.001\n",
        "config_dict['batch_size']=32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C7jQUGhXMNz"
      },
      "outputs": [],
      "source": [
        "config_dict['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcP1dftJWBDJ"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            setattr(self, key, value)\n",
        "config = Config(dictionary=config_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SUxEiAYpWGye"
      },
      "source": [
        "## (4) Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ufOTX0qPWTd7"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_heads, dropout_rate):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.multihead_attention = nn.MultiheadAttention(input_size, num_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm(input_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(input_size, 4*input_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*input_size, output_size),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(output_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head Attention\n",
        "        attn_output, _ = self.multihead_attention(x, x, x)\n",
        "        x = self.layer_norm1(x + attn_output)\n",
        "\n",
        "        # Feed-Forward Network\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.layer_norm2(x + ff_output)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads=8, dropout_rate=0.2, num_layers=3):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(d_model, d_model, num_heads, dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            x = transformer_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-bs1PhSWDMz"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, dropout=0.2, hidden_units=[512, 256,128]):\n",
        "        super(MLP, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(hidden_units) - 1):\n",
        "            self.layers.append(nn.Linear(hidden_units[i], hidden_units[i + 1]))\n",
        "            self.layers.append(nn.LeakyReLU())\n",
        "            self.layers.append(nn.Dropout(p=dropout))\n",
        "        self.fc = nn.Linear(hidden_units[-1],1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        logits = self.fc(x)\n",
        "        output = self.sigmoid(logits)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iV7-dBeeWa0k"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BSTRecommender(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BSTRecommender, self).__init__()\n",
        "        self.config = config\n",
        "        self.embed_configs = config.embed_configs\n",
        "        self.drouput = config.dropout\n",
        "        self.transformer_num_layer = config.transformer_num_layer\n",
        "        self.device = config.device\n",
        "\n",
        "        \"\"\"embed_configs\n",
        "        {'user': {'embed_dim': 32, 'num_embed': 6041},\n",
        "        'movie': {'embed_dim': 32, 'num_embed': 3884},\n",
        "        'occupation': {'embed_dim': 32, 'num_embed': 22},\n",
        "        'age_group': {'embed_dim': 32, 'num_embed': 8},\n",
        "        'position': {'embed_dim': 32, 'num_embed': 4}}\n",
        "        \"\"\"\n",
        "\n",
        "        embed_configs = self.config.embed_configs\n",
        "\n",
        "        \"\"\"Create Embedding Layer\"\"\"\n",
        "        embedding_layers = []\n",
        "        for name, embed_config in embed_configs.items():\n",
        "            embed_dim = embed_config['embed_dim']\n",
        "            num_embed = embed_config['num_embed']\n",
        "            embeding_layer = nn.Embedding(\n",
        "                num_embeddings=num_embed, embedding_dim=embed_dim)\n",
        "            nn.init.xavier_uniform_(embeding_layer.weight)\n",
        "            embedding_layers.append([name, embeding_layer])\n",
        "\n",
        "        self.embedding_layers = nn.ModuleDict(embedding_layers)\n",
        "\n",
        "        transformer_dim = self.embed_configs['position']['embed_dim'] + \\\n",
        "            self.embed_configs['movie']['embed_dim']\n",
        "\n",
        "        self.transformer_layer = TransformerLayer(d_model=transformer_dim,\n",
        "                                                  num_heads=8,\n",
        "                                                  dropout_rate=self.drouput,\n",
        "                                                  num_layers=self.transformer_num_layer)\n",
        "\n",
        "        # movie_embed_dim*2 + sequence*movie_embedding*2 + user_embed_dim*2+occupation_embed_dim*2+age_embed_dim*2+1\n",
        "\n",
        "        sequence_length = self.embed_configs['position']['num_embed']\n",
        "        mlp_dim = self.embed_configs['user']['embed_dim']*2 + \\\n",
        "            self.embed_configs['occupation']['embed_dim']*2 +\\\n",
        "            self.embed_configs['age_group']['embed_dim']*2 +\\\n",
        "            self.embed_configs['movie']['embed_dim']*2 +\\\n",
        "            transformer_dim*sequence_length+1\n",
        "\n",
        "        self.mlp = MLP(dropout=self.drouput, hidden_units=[mlp_dim, 256, 64])\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        target_movie_embedding = self.embedding_layers['movie'](\n",
        "            inputs['target_movie'])\n",
        "        batch_size = target_movie_embedding.shape[0]\n",
        "\n",
        "        \"\"\"Sequence Feature Engineering\"\"\"\n",
        "\n",
        "        # movie embedding\n",
        "        movie_sequence_embedding = self.embedding_layers['movie'](\n",
        "            inputs['movie_sequence'])\n",
        "\n",
        "        # position embedding\n",
        "        positions = torch.arange(\n",
        "            self.config.embed_configs['position']['num_embed']).to(self.device)\n",
        "        position_embedding = self.embedding_layers['position'](positions)\n",
        "        batch_position_embedding = torch.stack(\n",
        "            [position_embedding.clone() for _ in range(batch_size)])\n",
        "        # concat with position instead of adding\n",
        "        movie_pos_seq_embedding = torch.concat(\n",
        "            [movie_sequence_embedding, batch_position_embedding], dim=-1)\n",
        "        # point wise product with sequence rating\n",
        "        rating_sequence = inputs['rating_sequence']\n",
        "        movie_pos_rating_seq_embedding = torch.mul(\n",
        "            movie_pos_seq_embedding, rating_sequence.unsqueeze(-1))\n",
        "        # feed into transformer layer\n",
        "        seq_transformer_output = self.transformer_layer(\n",
        "            movie_pos_rating_seq_embedding)\n",
        "        seq_transformer_flatten_output = seq_transformer_output.view(\n",
        "            batch_size, -1)\n",
        "\n",
        "        \"\"\"concat other features\"\"\"\n",
        "        # orginal features\n",
        "        sex_feature = inputs['sex'].unsqueeze(-1)\n",
        "        user_embedding = self.embedding_layers['user'](inputs['user_id_index'])\n",
        "        occupation_embedding = self.embedding_layers['occupation'](\n",
        "            inputs['occupation_index'])\n",
        "        age_group_embedding = self.embedding_layers['age_group'](\n",
        "            inputs['age_group_index'])\n",
        "\n",
        "        # cross features with target movie embedding\n",
        "        sex_cross_feature = torch.mul(sex_feature, target_movie_embedding)\n",
        "        user_embedding_cross = torch.mul(\n",
        "            user_embedding, target_movie_embedding)\n",
        "        occupation_embedding_cross = torch.mul(\n",
        "            occupation_embedding, target_movie_embedding,)\n",
        "        age_group_embedding_cross = torch.mul(\n",
        "            age_group_embedding, target_movie_embedding)\n",
        "\n",
        "        # shape:1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_features = torch.concat(\n",
        "            [sex_feature, user_embedding, occupation_embedding, age_group_embedding], dim=-1)\n",
        "\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_cross_features = torch.concat(\n",
        "            [sex_cross_feature, user_embedding_cross, occupation_embedding_cross, age_group_embedding_cross], dim=-1)\n",
        "\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim + 1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_inputs_features = torch.concat(\n",
        "            [user_features, user_cross_features, target_movie_embedding], axis=1)\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim + 1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        # sequence*movie_embedding*2+movie_embeddding\n",
        "        mlp_input_features = torch.concat(\n",
        "            [user_inputs_features, seq_transformer_flatten_output], axis=1)\n",
        "\n",
        "        outputs = self.mlp(mlp_input_features)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2RO3K24Wdd2"
      },
      "outputs": [],
      "source": [
        "model = BSTRecommender(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpc5cAMKXVkN",
        "outputId": "ee065bd7-1b08-492b-8e22-b4f169ebfc42"
      },
      "outputs": [],
      "source": [
        "model = model.to(config.device)\n",
        "model.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iMu3zDCYWqwr"
      },
      "source": [
        "## (5) Load Rating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyeeVf7tWty1"
      },
      "outputs": [],
      "source": [
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        item_dict = self.data.iloc[index].to_dict()\n",
        "\n",
        "        dtype_dict = {}\n",
        "        for k,v in item_dict.items():\n",
        "            dtype_dict[k]=torch.long\n",
        "        dtype_dict['rating_sequence']=torch.float32\n",
        "        dtype_dict['target_rating']=torch.float32\n",
        "        dtype_dict['sex']=torch.float32\n",
        "\n",
        "\n",
        "        sample = {}\n",
        "        for k,v in item_dict.items():\n",
        "            sample[k] = torch.tensor(v,dtype=dtype_dict[k]).to(self.device)\n",
        "\n",
        "        return sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6qbyM5pWmke"
      },
      "outputs": [],
      "source": [
        "train_dataset = RatingDataset(data=train_data)\n",
        "test_dataset = RatingDataset(data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ggs147hXj43"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=config.batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=config.batch_size,shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bddyOJ1OZuiM"
      },
      "source": [
        "## (6) Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AYv7XU1ZIfn"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjUtHjQQY9Zv"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,dataset_loader,min_max_scaler,loss_func=nn.L1Loss()):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    prob_list= []\n",
        "    rating_list = []\n",
        "    eval_loss_list = []\n",
        "\n",
        "\n",
        "    # loss_func = nn.MSELoss()\n",
        "\n",
        "    pbar = tqdm(total = len(dataset_loader),desc = \"\",position=0, leave=True)\n",
        "\n",
        "    for inputs in dataset_loader:\n",
        "        with torch.no_grad():\n",
        "            probs = model(inputs)\n",
        "            ratings = inputs['target_rating'].view(-1,1)\n",
        "\n",
        "            loss = loss_func(probs, ratings)\n",
        "            eval_loss_list.append(loss.item())\n",
        "\n",
        "            probs = probs.cpu().numpy().flatten().tolist()\n",
        "            prob_list.extend(probs)\n",
        "\n",
        "            ratings = ratings.cpu().numpy().flatten().tolist()\n",
        "            rating_list.extend(ratings)\n",
        "            \n",
        "\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    real_ratings =min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "    prediction_ratings=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]\n",
        "\n",
        "    MAE = metrics.mean_absolute_error(real_ratings,prediction_ratings)\n",
        "    RMSE = metrics.mean_squared_error(real_ratings,prediction_ratings)\n",
        "    \n",
        "\n",
        "    eval_metrics = {}\n",
        "    eval_metrics['eval_loss']= sum(eval_loss_list)/len(eval_loss_list)\n",
        "    eval_metrics['eval_MAE']= MAE\n",
        "    eval_metrics['eval_RMSE']= RMSE\n",
        "\n",
        "\n",
        "    return eval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quf-eGpiZWPQ",
        "outputId": "6d219858-1624-4511-8e84-f55c88c12861"
      },
      "outputs": [],
      "source": [
        "# loss before training\n",
        "before_training_metrics = evaluate(model,test_loader,min_max_scaler,loss_func)\n",
        "print(before_training_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFHm_mNFZZyq"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),lr=config.learning_rate)\n",
        "total_batch = 0\n",
        "best_eval_loss =  float(\"inf\")\n",
        "best_checkpoint = 0\n",
        "model_version='v1'\n",
        "config.eval_steps = len(train_loader)//3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTP7eC6SaJG1"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_save_dir,step,model_metrics):\n",
        "    model_save_dir = os.path.join(model_save_dir,f\"checkpoint-{step}\")\n",
        "    model_name = \"pytorch_model.pt\"\n",
        "    train_state_name = \"training_state.json\"\n",
        "    os.makedirs(model_save_dir,exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_save_dir,model_name)\n",
        "    train_state_path = os.path.join(model_save_dir,train_state_name)\n",
        "\n",
        "    torch.save(model.state_dict(),model_path)\n",
        "\n",
        "    if model_metrics is not None:\n",
        "        with open(train_state_path,mode = 'w',encoding = 'utf-8') as f:\n",
        "            json.dump(model_metrics,f,indent=4)\n",
        "\n",
        "    return model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN2ILumCaAOh",
        "outputId": "ce510b50-2e69-4568-db0b-f94a0b4cdf9b"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "total_pbar = tqdm(total=len(train_loader)*config.epoches,\n",
        "                  desc=\"Training\", position=0, leave=True)\n",
        "\n",
        "metrics_list = []\n",
        "best_model_path= None\n",
        "for epoch in range(config.epoches):\n",
        "    # print(\"*\"*50 + f\"epoch: {epoch + 1}\" + \"*\"*50)\n",
        "\n",
        "    train_loss_list = []\n",
        "    prob_list = []\n",
        "    rating_list = []\n",
        "\n",
        "    for inputs in train_loader:\n",
        "        model = model.train()\n",
        "        optimizer.zero_grad()\n",
        "        probs = model(inputs)\n",
        "\n",
        "        rating = inputs['target_rating'].view(-1, 1)\n",
        "\n",
        "        loss = loss_func(probs, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "        probs = probs.detach().cpu().numpy().flatten().tolist()\n",
        "        prob_list.extend(probs)\n",
        "        rating = rating.detach().cpu().flatten().tolist()\n",
        "        rating_list.extend(rating)\n",
        "\n",
        "        if (total_batch+1) % config.eval_steps == 0:\n",
        "\n",
        "            improve = False\n",
        "            model_metrics = evaluate(model, test_loader,min_max_scaler,loss_func)\n",
        "            eval_loss = model_metrics['eval_loss']\n",
        "\n",
        "            if eval_loss <= best_eval_loss:\n",
        "                improve = True\n",
        "                best_checkpoint = total_batch+1\n",
        "                best_eval_loss = eval_loss\n",
        "\n",
        "            train_loss = np.mean(train_loss_list)\n",
        "            \n",
        "            real_ratings =min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "            prediction_ratings=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]\n",
        "            MAE = metrics.mean_absolute_error(real_ratings,prediction_ratings)\n",
        "            RMSE = metrics.mean_squared_error(real_ratings,prediction_ratings)\n",
        "\n",
        "            model_metrics['best_eval_loss'] = best_eval_loss\n",
        "            model_metrics['train_loss'] = train_loss\n",
        "            model_metrics['train_MAE'] = MAE\n",
        "            model_metrics['train_RMSE'] = RMSE\n",
        "            \n",
        "            model_metrics[\"steps\"] = total_batch+1\n",
        "            model_metrics[\"best_checkpoint\"] = best_checkpoint\n",
        "            metrics_list.append(model_metrics)\n",
        "\n",
        "            if improve:\n",
        "                save_dir = os.path.join(\"models\", model_version)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                model_path = save_model(model, save_dir, total_batch+1, model_metrics)\n",
        "                best_model_path = model_path\n",
        "            post_fix_message = {k:round(v,3) for k,v in model_metrics.items()}\n",
        "            total_pbar.set_postfix(post_fix_message)\n",
        "\n",
        "\n",
        "            model = model.train()\n",
        "\n",
        "        total_batch += 1\n",
        "        total_pbar.update(1)\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "total_pbar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzfHrJl6aP0t"
      },
      "outputs": [],
      "source": [
        "df_metrics = pd.DataFrame(metrics_list)\n",
        "df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_metrics = df_metrics.set_index(\"steps\")\n",
        "df_metrics[['eval_loss','train_loss']].plot() "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (7) Validate Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = BSTRecommender(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.load_state_dict(torch.load(best_model_path))\n",
        "best_model.eval()\n",
        "best_model.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.eval()\n",
        "prob_list= []\n",
        "rating_list = []\n",
        "eval_loss_list = []\n",
        "pbar = tqdm(total = len(test_loader),desc = \"\",position=0, leave=True)\n",
        "for inputs in test_loader:\n",
        "    with torch.no_grad():\n",
        "        probs = best_model(inputs)\n",
        "        ratings = inputs['target_rating'].view(-1,1)\n",
        "        \n",
        "        loss = loss_func(probs, ratings)\n",
        "        eval_loss_list.append(loss.item())\n",
        "\n",
        "        probs = probs.cpu().numpy().flatten().tolist()\n",
        "        prob_list.extend(probs)\n",
        "\n",
        "        ratings = ratings.cpu().numpy().flatten().tolist()\n",
        "        rating_list.extend(ratings)\n",
        "\n",
        "        pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = pd.DataFrame()\n",
        "prediction['real']=min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "prediction['prediction']=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAE = metrics.mean_absolute_error(prediction['real'],prediction['prediction'])\n",
        "RMSE = metrics.mean_squared_error(prediction['real'],prediction['prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"MAE:{MAE},RMSE:{RMSE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"show result: the model seems very good\"\"\"\n",
        "prediction.iloc[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
