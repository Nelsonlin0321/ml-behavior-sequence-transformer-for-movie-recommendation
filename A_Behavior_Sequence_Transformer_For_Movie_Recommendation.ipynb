{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aUG4oG3JSGCn"
      },
      "source": [
        "# A Behavior Sequence Transformer For Movie Recommendation\n",
        "\n",
        "**Author:** [Nelson Lin](https://www.linkedin.com/in/nelson-lin-842564164/)<br>\n",
        "**Date created:** 2024/07/09<br>\n",
        "**Last modified:** 2024/07/09<br>\n",
        "**Description:** Rating rate prediction using the Behavior Sequence Transformer (BST) model on the Movielens 1M."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "10UcMwj-Sjqv"
      },
      "source": [
        "## (1) Notebook Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RxoBk0OkSvPn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from zipfile import ZipFile\n",
        "from urllib.request import urlretrieve\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import json\n",
        "from sklearn import metrics\n",
        "from uuid import uuid4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_RHfTP4S3IZ"
      },
      "source": [
        "## (2) Data preparation"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm747EdZU1bZ"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KrasdLSrSG1x"
      },
      "outputs": [],
      "source": [
        "# urlretrieve(\"http://files.grouplens.org/datasets/movielens/ml-1m.zip\", \"movielens.zip\")\n",
        "# ZipFile(\"movielens.zip\", \"r\").extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c8YFIdZeSxaH"
      },
      "outputs": [],
      "source": [
        "users = pd.read_csv(\n",
        "    \"ml-1m/users.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"sex\", \"age_group\", \"occupation\", \"zip_code\"],\n",
        "    engine='python'\n",
        ")\n",
        "\n",
        "ratings = pd.read_csv(\n",
        "    \"ml-1m/ratings.dat\",\n",
        "    sep=\"::\",\n",
        "    names=[\"user_id\", \"movie_id\", \"rating\", \"unix_timestamp\"],\n",
        "    engine='python'\n",
        ")\n",
        "\n",
        "movies = pd.read_csv(\n",
        "    \"ml-1m/movies.dat\", sep=\"::\", names=[\"movie_id\", \"title\", \"genres\"],\n",
        "    engine='python',encoding='ISO-8859-1'\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MMRanAvKU9t1"
      },
      "source": [
        "### Remap ID to index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AxDgQLlHS17f"
      },
      "outputs": [],
      "source": [
        "# remap the id to index\n",
        "def generate_remap_id_dict(df,col):\n",
        "    ids = df[df[col].notnull()][col].unique().tolist()\n",
        "    ids = sorted(ids)\n",
        "    id_map_dict = {x: i+1 for i, x in enumerate(ids)}\n",
        "    id_map_dict[\"UNK\"]=0\n",
        "\n",
        "    df[f\"{col}_index\"] = df[col].fillna(\"UNK\").map(id_map_dict)\n",
        "\n",
        "    return id_map_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9sCplGKlTHHt"
      },
      "outputs": [],
      "source": [
        "user_id_map_dict = generate_remap_id_dict(users,col='user_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jl_-Q_yYUA-6",
        "outputId": "a37170ca-c76f-4d1c-e1e8-1cdcd42e5c0a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>sex</th>\n",
              "      <th>age_group</th>\n",
              "      <th>occupation</th>\n",
              "      <th>zip_code</th>\n",
              "      <th>user_id_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>48067</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>56</td>\n",
              "      <td>16</td>\n",
              "      <td>70072</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>55117</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>02460</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>55455</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id sex  age_group  occupation zip_code  user_id_index\n",
              "0        1   F          1          10    48067              1\n",
              "1        2   M         56          16    70072              2\n",
              "2        3   M         25          15    55117              3\n",
              "3        4   M         45           7    02460              4\n",
              "4        5   M         25          20    55455              5"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "users.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hsCN2BJ0UAQC"
      },
      "outputs": [],
      "source": [
        "# remap sex to score\n",
        "sex_id_map_dict = {'M':0.0,'F':1.0,'UNK':0.5}\n",
        "users['sex']=users['sex'].map(sex_id_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ssHECS9iTZ3A"
      },
      "outputs": [],
      "source": [
        "occupation_id_map_dict = generate_remap_id_dict(users,col='occupation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dGTwjedfTfN1"
      },
      "outputs": [],
      "source": [
        "age_group_id_map_dict = generate_remap_id_dict(users,col='age_group')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NRtH_iAeTgn0"
      },
      "outputs": [],
      "source": [
        "min_max_scaler = MinMaxScaler()\n",
        "ratings[\"norm_rating\"] = min_max_scaler.fit_transform(\n",
        "    ratings[\"rating\"].values.reshape(-1, 1))[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gqur_n48Trck"
      },
      "outputs": [],
      "source": [
        "movie_id_map_dict = generate_remap_id_dict(movies,col='movie_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DSu3fNkyTv6D"
      },
      "outputs": [],
      "source": [
        "genres_set = set()\n",
        "def get_genres_set(genres):\n",
        "    global genres_set\n",
        "    genres_split = genres.split(\"|\")\n",
        "    genres_set.update(genres_split)\n",
        "    return genres_split\n",
        "movies['genres'] = movies['genres'].apply(lambda x:get_genres_set(x))\n",
        "genres_map_dict ={x: i+1 for i, x in enumerate(sorted(genres_set))}\n",
        "genres_map_dict['UNK']=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hD5T2WuYUUuB"
      },
      "outputs": [],
      "source": [
        "movies['genres_ids']= movies['genres'].apply(lambda x: [genres_map_dict[g] for g in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qbMexz0nUPyz"
      },
      "outputs": [],
      "source": [
        "ratings['movie_id_index'] = ratings['movie_id'].map(movie_id_map_dict)\n",
        "ratings['user_id_index'] = ratings['user_id'].map(user_id_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "0NW-x8FdTy40"
      },
      "outputs": [],
      "source": [
        "df_user_views = ratings[[\"movie_id_index\", \"user_id_index\", \"unix_timestamp\", \"norm_rating\"]] \\\n",
        "    .merge(movies[['movie_id_index', 'genres_ids']],\n",
        "           on=['movie_id_index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QM1VX4lVUMMa",
        "outputId": "aca32242-4f66-4be8-bdab-669ab38d1a26"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id_index</th>\n",
              "      <th>user_id_index</th>\n",
              "      <th>unix_timestamp</th>\n",
              "      <th>norm_rating</th>\n",
              "      <th>genres_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1177</td>\n",
              "      <td>1</td>\n",
              "      <td>978300760</td>\n",
              "      <td>1.00</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1177</td>\n",
              "      <td>2</td>\n",
              "      <td>978298413</td>\n",
              "      <td>1.00</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1177</td>\n",
              "      <td>12</td>\n",
              "      <td>978220179</td>\n",
              "      <td>0.75</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1177</td>\n",
              "      <td>15</td>\n",
              "      <td>978199279</td>\n",
              "      <td>0.75</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1177</td>\n",
              "      <td>17</td>\n",
              "      <td>978158471</td>\n",
              "      <td>1.00</td>\n",
              "      <td>[8]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movie_id_index  user_id_index  unix_timestamp  norm_rating genres_ids\n",
              "0            1177              1       978300760         1.00        [8]\n",
              "1            1177              2       978298413         1.00        [8]\n",
              "2            1177             12       978220179         0.75        [8]\n",
              "3            1177             15       978199279         0.75        [8]\n",
              "4            1177             17       978158471         1.00        [8]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_user_views.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o2uoGM6uUsKF"
      },
      "source": [
        "### Prepare the Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DvQBp4moVNEf"
      },
      "outputs": [],
      "source": [
        "df_agg_ratings = df_user_views.sort_values(by=[\"unix_timestamp\"]).groupby(\"user_id_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "44_d1f5pVSqX"
      },
      "outputs": [],
      "source": [
        "ratings_data = pd.DataFrame(\n",
        "    data={\n",
        "        \"user_id_index\": list(df_agg_ratings.groups.keys()),\n",
        "        \"movie_sequence\": list(df_agg_ratings.movie_id_index.apply(list)),\n",
        "        \"rating_sequence\": list(df_agg_ratings.norm_rating.apply(list)),\n",
        "        \"timestamps\": list(df_agg_ratings.unix_timestamp.apply(list)),\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LrruVMSyUxXW"
      },
      "outputs": [],
      "source": [
        "sequence_length =4\n",
        "step_size = 2\n",
        "\n",
        "\n",
        "def create_sequences(values, window_size, step_size):\n",
        "    sequences = []\n",
        "    start_index = 0\n",
        "    while True:\n",
        "        end_index = start_index + window_size\n",
        "        seq = values[start_index:end_index]\n",
        "        if len(seq) < window_size:\n",
        "            seq = values[-window_size:]\n",
        "            if len(seq) == window_size:\n",
        "                sequences.append(seq)\n",
        "            break\n",
        "        sequences.append(seq)\n",
        "        start_index += step_size\n",
        "    return sequences\n",
        "\n",
        "\n",
        "ratings_data.movie_sequence\t = ratings_data.movie_sequence.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "ratings_data.rating_sequence = ratings_data.rating_sequence.apply(\n",
        "    lambda ids: create_sequences(ids, sequence_length, step_size)\n",
        ")\n",
        "\n",
        "del ratings_data[\"timestamps\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eREuVC30VU03"
      },
      "outputs": [],
      "source": [
        "ratings_data_movies = ratings_data[[\"user_id_index\", \"movie_sequence\"]].explode(\n",
        "    \"movie_sequence\", ignore_index=True\n",
        ")\n",
        "ratings_data_rating = ratings_data[[\"rating_sequence\"]].explode(\"rating_sequence\", ignore_index=True)\n",
        "ratings_data_transformed = pd.concat([ratings_data_movies, ratings_data_rating], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "K-yTVNctVWbn",
        "outputId": "d51b685b-cc56-4caf-f201-729232ee2c2f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id_index</th>\n",
              "      <th>movie_sequence</th>\n",
              "      <th>rating_sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[3118, 1010, 1673, 1251]</td>\n",
              "      <td>[0.75, 1.0, 0.75, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1673, 1251, 2272, 1769]</td>\n",
              "      <td>[0.75, 1.0, 0.5, 1.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[2272, 1769, 3340, 1190]</td>\n",
              "      <td>[0.5, 1.0, 0.75, 0.75]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[3340, 1190, 2736, 258]</td>\n",
              "      <td>[0.75, 0.75, 1.0, 0.75]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[2736, 258, 1177, 712]</td>\n",
              "      <td>[1.0, 0.75, 1.0, 0.5]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id_index            movie_sequence          rating_sequence\n",
              "0              1  [3118, 1010, 1673, 1251]   [0.75, 1.0, 0.75, 1.0]\n",
              "1              1  [1673, 1251, 2272, 1769]    [0.75, 1.0, 0.5, 1.0]\n",
              "2              1  [2272, 1769, 3340, 1190]   [0.5, 1.0, 0.75, 0.75]\n",
              "3              1   [3340, 1190, 2736, 258]  [0.75, 0.75, 1.0, 0.75]\n",
              "4              1    [2736, 258, 1177, 712]    [1.0, 0.75, 1.0, 0.5]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_data_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "roXPTpv8VY-9"
      },
      "outputs": [],
      "source": [
        "user_columns = ['user_id_index',\n",
        "                'sex',\n",
        "                'occupation_index',\n",
        "                'age_group_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "kotYicQYVaGe"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed = ratings_data_transformed.merge(\n",
        "    users[user_columns], on=\"user_id_index\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "GUE9Aj-JVbB_"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed['sex'] = ratings_data_transformed['sex'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "-f6yhP5ZVcPk"
      },
      "outputs": [],
      "source": [
        "ratings_data_transformed['target_movie'] =  ratings_data_transformed['movie_sequence'].apply(lambda x:x[-1])\n",
        "ratings_data_transformed['target_rating'] =  ratings_data_transformed['rating_sequence'].apply(lambda x:x[-1])\n",
        "# mask the last rating\n",
        "mask_score = 1.0\n",
        "ratings_data_transformed['rating_sequence'] =  ratings_data_transformed['rating_sequence'].apply(lambda x:x[:-1]+[mask_score])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_D1bExqMVkRd",
        "outputId": "c23bbf8a-0b53-47bc-fc80-82cb54374ba1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id_index</th>\n",
              "      <th>movie_sequence</th>\n",
              "      <th>rating_sequence</th>\n",
              "      <th>sex</th>\n",
              "      <th>occupation_index</th>\n",
              "      <th>age_group_index</th>\n",
              "      <th>target_movie</th>\n",
              "      <th>target_rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[3118, 1010, 1673, 1251]</td>\n",
              "      <td>[0.75, 1.0, 0.75, 1.0]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1251</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[1673, 1251, 2272, 1769]</td>\n",
              "      <td>[0.75, 1.0, 0.5, 1.0]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1769</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>[2272, 1769, 3340, 1190]</td>\n",
              "      <td>[0.5, 1.0, 0.75, 1.0]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1190</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>[3340, 1190, 2736, 258]</td>\n",
              "      <td>[0.75, 0.75, 1.0, 1.0]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>258</td>\n",
              "      <td>0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>[2736, 258, 1177, 712]</td>\n",
              "      <td>[1.0, 0.75, 1.0, 1.0]</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>712</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id_index            movie_sequence         rating_sequence  sex  \\\n",
              "0              1  [3118, 1010, 1673, 1251]  [0.75, 1.0, 0.75, 1.0]  1.0   \n",
              "1              1  [1673, 1251, 2272, 1769]   [0.75, 1.0, 0.5, 1.0]  1.0   \n",
              "2              1  [2272, 1769, 3340, 1190]   [0.5, 1.0, 0.75, 1.0]  1.0   \n",
              "3              1   [3340, 1190, 2736, 258]  [0.75, 0.75, 1.0, 1.0]  1.0   \n",
              "4              1    [2736, 258, 1177, 712]   [1.0, 0.75, 1.0, 1.0]  1.0   \n",
              "\n",
              "   occupation_index  age_group_index  target_movie  target_rating  \n",
              "0                11                1          1251           1.00  \n",
              "1                11                1          1769           1.00  \n",
              "2                11                1          1190           0.75  \n",
              "3                11                1           258           0.75  \n",
              "4                11                1           712           0.50  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ratings_data_transformed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bQEmshcNVlks"
      },
      "outputs": [],
      "source": [
        "random_selection = np.random.rand(len(ratings_data_transformed.index)) <= 0.85\n",
        "train_data = ratings_data_transformed[random_selection]\n",
        "test_data = ratings_data_transformed[~random_selection]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bXqZBv7BVv4v"
      },
      "source": [
        "## (3) Model Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "74j7Qs7LVxkF"
      },
      "outputs": [],
      "source": [
        "num_user = len(user_id_map_dict)\n",
        "num_movie = len(movie_id_map_dict)\n",
        "num_occupation = len(occupation_id_map_dict)\n",
        "num_age_group = len(age_group_id_map_dict)\n",
        "# num_genre = len(genres_map_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "K4MOe95uV2qg"
      },
      "outputs": [],
      "source": [
        "embed_configs = {}\n",
        "EMED_DIM=32\n",
        "embed_configs['user']={\"embed_dim\":EMED_DIM,\"num_embed\":num_user}\n",
        "embed_configs['movie']={\"embed_dim\":EMED_DIM,\"num_embed\":num_movie}\n",
        "embed_configs['occupation']={\"embed_dim\":EMED_DIM,\"num_embed\":num_occupation}\n",
        "embed_configs['age_group']={\"embed_dim\":EMED_DIM,\"num_embed\":num_age_group}\n",
        "embed_configs['position'] = {\"embed_dim\":EMED_DIM,\"num_embed\":sequence_length}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6p7ikk9DV_od"
      },
      "outputs": [],
      "source": [
        "config_dict={}\n",
        "config_dict['embed_configs'] = embed_configs\n",
        "config_dict['transformer_num_layer']=3\n",
        "config_dict['dropout']=0.2\n",
        "config_dict['epoches']=10\n",
        "config_dict['learning_rate']=0.001\n",
        "config_dict['batch_size']=128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "3C7jQUGhXMNz"
      },
      "outputs": [],
      "source": [
        "config_dict['device'] = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "YcP1dftJWBDJ"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self, dictionary):\n",
        "        for key, value in dictionary.items():\n",
        "            setattr(self, key, value)\n",
        "config = Config(dictionary=config_dict)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SUxEiAYpWGye"
      },
      "source": [
        "## (4) Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ufOTX0qPWTd7"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_heads, dropout_rate):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.multihead_attention = nn.MultiheadAttention(input_size, num_heads)\n",
        "        self.layer_norm1 = nn.LayerNorm(input_size)\n",
        "\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(input_size, 4*input_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4*input_size, output_size),\n",
        "            nn.Dropout(dropout_rate)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(output_size)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head Attention\n",
        "        attn_output, _ = self.multihead_attention(x, x, x)\n",
        "        x = self.layer_norm1(x + attn_output)\n",
        "\n",
        "        # Feed-Forward Network\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = self.layer_norm2(x + ff_output)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class TransformerLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads=8, dropout_rate=0.2, num_layers=3):\n",
        "        super(TransformerLayer, self).__init__()\n",
        "\n",
        "        self.transformer_blocks = nn.ModuleList([\n",
        "            TransformerBlock(d_model, d_model, num_heads, dropout_rate)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            x = transformer_block(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "2-bs1PhSWDMz"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, dropout=0.2, hidden_units=[512, 256,128]):\n",
        "        super(MLP, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.layers = nn.ModuleList()\n",
        "        for i in range(len(hidden_units) - 1):\n",
        "            self.layers.append(nn.Linear(hidden_units[i], hidden_units[i + 1]))\n",
        "            self.layers.append(nn.LeakyReLU())\n",
        "            self.layers.append(nn.Dropout(p=dropout))\n",
        "        self.fc = nn.Linear(hidden_units[-1],1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        logits = self.fc(x)\n",
        "        output = self.sigmoid(logits)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "iV7-dBeeWa0k"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BSTRecommender(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(BSTRecommender, self).__init__()\n",
        "        self.config = config\n",
        "        self.embed_configs = config.embed_configs\n",
        "        self.drouput = config.dropout\n",
        "        self.transformer_num_layer = config.transformer_num_layer\n",
        "        self.device = config.device\n",
        "\n",
        "        \"\"\"embed_configs\n",
        "        {'user': {'embed_dim': 32, 'num_embed': 6041},\n",
        "        'movie': {'embed_dim': 32, 'num_embed': 3884},\n",
        "        'occupation': {'embed_dim': 32, 'num_embed': 22},\n",
        "        'age_group': {'embed_dim': 32, 'num_embed': 8},\n",
        "        'position': {'embed_dim': 32, 'num_embed': 4}}\n",
        "        \"\"\"\n",
        "\n",
        "        embed_configs = self.config.embed_configs\n",
        "\n",
        "        \"\"\"Create Embedding Layer\"\"\"\n",
        "        embedding_layers = []\n",
        "        for name, embed_config in embed_configs.items():\n",
        "            embed_dim = embed_config['embed_dim']\n",
        "            num_embed = embed_config['num_embed']\n",
        "            embeding_layer = nn.Embedding(\n",
        "                num_embeddings=num_embed, embedding_dim=embed_dim)\n",
        "            nn.init.xavier_uniform_(embeding_layer.weight)\n",
        "            embedding_layers.append([name, embeding_layer])\n",
        "\n",
        "        self.embedding_layers = nn.ModuleDict(embedding_layers)\n",
        "\n",
        "        transformer_dim = self.embed_configs['position']['embed_dim'] + \\\n",
        "            self.embed_configs['movie']['embed_dim']\n",
        "\n",
        "        self.transformer_layer = TransformerLayer(d_model=transformer_dim,\n",
        "                                                  num_heads=8,\n",
        "                                                  dropout_rate=self.drouput,\n",
        "                                                  num_layers=self.transformer_num_layer)\n",
        "\n",
        "        # movie_embed_dim*2 + sequence*movie_embedding*2 + user_embed_dim*2+occupation_embed_dim*2+age_embed_dim*2+1\n",
        "\n",
        "        sequence_length = self.embed_configs['position']['num_embed']\n",
        "        mlp_dim = self.embed_configs['user']['embed_dim']*2 + \\\n",
        "            self.embed_configs['occupation']['embed_dim']*2 +\\\n",
        "            self.embed_configs['age_group']['embed_dim']*2 +\\\n",
        "            self.embed_configs['movie']['embed_dim']*2 +\\\n",
        "            transformer_dim*sequence_length+1\n",
        "\n",
        "        self.mlp = MLP(dropout=self.drouput, hidden_units=[mlp_dim, 256, 64])\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        target_movie_embedding = self.embedding_layers['movie'](\n",
        "            inputs['target_movie'])\n",
        "        batch_size = target_movie_embedding.shape[0]\n",
        "\n",
        "        \"\"\"Sequence Feature Engineering\"\"\"\n",
        "\n",
        "        # movie embedding\n",
        "        movie_sequence_embedding = self.embedding_layers['movie'](\n",
        "            inputs['movie_sequence'])\n",
        "\n",
        "        # position embedding\n",
        "        positions = torch.arange(\n",
        "            self.config.embed_configs['position']['num_embed']).to(self.device)\n",
        "        position_embedding = self.embedding_layers['position'](positions)\n",
        "        batch_position_embedding = torch.stack(\n",
        "            [position_embedding.clone() for _ in range(batch_size)])\n",
        "        # concat with position instead of adding\n",
        "        movie_pos_seq_embedding = torch.concat(\n",
        "            [movie_sequence_embedding, batch_position_embedding], dim=-1)\n",
        "        # point wise product with sequence rating\n",
        "        rating_sequence = inputs['rating_sequence']\n",
        "        movie_pos_rating_seq_embedding = torch.mul(\n",
        "            movie_pos_seq_embedding, rating_sequence.unsqueeze(-1))\n",
        "        # feed into transformer layer\n",
        "        seq_transformer_output = self.transformer_layer(\n",
        "            movie_pos_rating_seq_embedding)\n",
        "        seq_transformer_flatten_output = seq_transformer_output.view(\n",
        "            batch_size, -1)\n",
        "\n",
        "        \"\"\"concat other features\"\"\"\n",
        "        # orginal features\n",
        "        sex_feature = inputs['sex'].unsqueeze(-1)\n",
        "        user_embedding = self.embedding_layers['user'](inputs['user_id_index'])\n",
        "        occupation_embedding = self.embedding_layers['occupation'](\n",
        "            inputs['occupation_index'])\n",
        "        age_group_embedding = self.embedding_layers['age_group'](\n",
        "            inputs['age_group_index'])\n",
        "\n",
        "        # cross features with target movie embedding\n",
        "        sex_cross_feature = torch.mul(sex_feature, target_movie_embedding)\n",
        "        user_embedding_cross = torch.mul(\n",
        "            user_embedding, target_movie_embedding)\n",
        "        occupation_embedding_cross = torch.mul(\n",
        "            occupation_embedding, target_movie_embedding,)\n",
        "        age_group_embedding_cross = torch.mul(\n",
        "            age_group_embedding, target_movie_embedding)\n",
        "\n",
        "        # shape:1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_features = torch.concat(\n",
        "            [sex_feature, user_embedding, occupation_embedding, age_group_embedding], dim=-1)\n",
        "\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_cross_features = torch.concat(\n",
        "            [sex_cross_feature, user_embedding_cross, occupation_embedding_cross, age_group_embedding_cross], dim=-1)\n",
        "\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim + 1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        user_inputs_features = torch.concat(\n",
        "            [user_features, user_cross_features, target_movie_embedding], axis=1)\n",
        "        # shape:movie_embed_dim +user_embed_dim+occupation_embed_dim+age_embed_dim + 1+user_embed_dim+occupation_embed_dim+age_embed_dim\n",
        "        # sequence*movie_embedding*2+movie_embeddding\n",
        "        mlp_input_features = torch.concat(\n",
        "            [user_inputs_features, seq_transformer_flatten_output], axis=1)\n",
        "\n",
        "        outputs = self.mlp(mlp_input_features)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "u2RO3K24Wdd2"
      },
      "outputs": [],
      "source": [
        "model = BSTRecommender(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpc5cAMKXVkN",
        "outputId": "ee065bd7-1b08-492b-8e22-b4f169ebfc42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BSTRecommender(\n",
              "  (embedding_layers): ModuleDict(\n",
              "    (user): Embedding(6041, 32)\n",
              "    (movie): Embedding(3884, 32)\n",
              "    (occupation): Embedding(22, 32)\n",
              "    (age_group): Embedding(8, 32)\n",
              "    (position): Embedding(4, 32)\n",
              "  )\n",
              "  (transformer_layer): TransformerLayer(\n",
              "    (transformer_blocks): ModuleList(\n",
              "      (0-2): 3 x TransformerBlock(\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp): MLP(\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=513, out_features=256, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "      (2): Dropout(p=0.2, inplace=False)\n",
              "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (4): LeakyReLU(negative_slope=0.01)\n",
              "      (5): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (fc): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = model.to(config.device)\n",
        "model.train()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iMu3zDCYWqwr"
      },
      "source": [
        "## (5) Load Rating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "KyeeVf7tWty1"
      },
      "outputs": [],
      "source": [
        "class RatingDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        item_dict = self.data.iloc[index].to_dict()\n",
        "\n",
        "        dtype_dict = {}\n",
        "        for k,v in item_dict.items():\n",
        "            dtype_dict[k]=torch.long\n",
        "        dtype_dict['rating_sequence']=torch.float32\n",
        "        dtype_dict['target_rating']=torch.float32\n",
        "        dtype_dict['sex']=torch.float32\n",
        "\n",
        "\n",
        "        sample = {}\n",
        "        for k,v in item_dict.items():\n",
        "            sample[k] = torch.tensor(v,dtype=dtype_dict[k]).to(self.device)\n",
        "\n",
        "        return sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G6qbyM5pWmke"
      },
      "outputs": [],
      "source": [
        "train_dataset = RatingDataset(data=train_data)\n",
        "test_dataset = RatingDataset(data=test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4ggs147hXj43"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=config.batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=config.batch_size,shuffle=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bddyOJ1OZuiM"
      },
      "source": [
        "## (6) Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6AYv7XU1ZIfn"
      },
      "outputs": [],
      "source": [
        "loss_func = nn.L1Loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "QjUtHjQQY9Zv"
      },
      "outputs": [],
      "source": [
        "def evaluate(model,dataset_loader,min_max_scaler,loss_func=nn.L1Loss()):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    prob_list= []\n",
        "    rating_list = []\n",
        "    eval_loss_list = []\n",
        "\n",
        "\n",
        "    # loss_func = nn.MSELoss()\n",
        "\n",
        "    pbar = tqdm(total = len(dataset_loader),desc = \"\",position=0, leave=True)\n",
        "\n",
        "    for inputs in dataset_loader:\n",
        "        with torch.no_grad():\n",
        "            probs = model(inputs)\n",
        "            ratings = inputs['target_rating'].view(-1,1)\n",
        "\n",
        "            loss = loss_func(probs, ratings)\n",
        "            eval_loss_list.append(loss.item())\n",
        "\n",
        "            probs = probs.cpu().numpy().flatten().tolist()\n",
        "            prob_list.extend(probs)\n",
        "\n",
        "            ratings = ratings.cpu().numpy().flatten().tolist()\n",
        "            rating_list.extend(ratings)\n",
        "            \n",
        "\n",
        "\n",
        "            pbar.update(1)\n",
        "\n",
        "    pbar.close()\n",
        "\n",
        "    real_ratings =min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "    prediction_ratings=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]\n",
        "\n",
        "    MAE = metrics.mean_absolute_error(real_ratings,prediction_ratings)\n",
        "    RMSE = metrics.mean_squared_error(real_ratings,prediction_ratings)\n",
        "    \n",
        "\n",
        "    eval_metrics = {}\n",
        "    eval_metrics['eval_loss']= sum(eval_loss_list)/len(eval_loss_list)\n",
        "    eval_metrics['eval_MAE']= MAE\n",
        "    eval_metrics['eval_RMSE']= RMSE\n",
        "\n",
        "\n",
        "    return eval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quf-eGpiZWPQ",
        "outputId": "6d219858-1624-4511-8e84-f55c88c12861"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/582 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 582/582 [00:11<00:00, 52.52it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.2516805342177755, 'eval_MAE': 1.0067355053647888, 'eval_RMSE': 1.443022877172972}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# loss before training\n",
        "before_training_metrics = evaluate(model,test_loader,min_max_scaler,loss_func)\n",
        "print(before_training_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lFHm_mNFZZyq"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),lr=config.learning_rate)\n",
        "total_batch = 0\n",
        "best_eval_loss =  float(\"inf\")\n",
        "best_checkpoint = 0\n",
        "model_version=str(uuid4())\n",
        "config.eval_steps = len(train_loader)//3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JTP7eC6SaJG1"
      },
      "outputs": [],
      "source": [
        "def save_model(model, model_save_dir,step,model_metrics):\n",
        "    model_save_dir = os.path.join(model_save_dir,f\"checkpoint-{step}\")\n",
        "    model_name = \"pytorch_model.pt\"\n",
        "    train_state_name = \"training_state.json\"\n",
        "    os.makedirs(model_save_dir,exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_save_dir,model_name)\n",
        "    train_state_path = os.path.join(model_save_dir,train_state_name)\n",
        "\n",
        "    torch.save(model.state_dict(),model_path)\n",
        "\n",
        "    if model_metrics is not None:\n",
        "        with open(train_state_path,mode = 'w',encoding = 'utf-8') as f:\n",
        "            json.dump(model_metrics,f,indent=4)\n",
        "\n",
        "    return model_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN2ILumCaAOh",
        "outputId": "ce510b50-2e69-4568-db0b-f94a0b4cdf9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 582/582 [00:11<00:00, 51.08it/s]1, 28.08it/s]\n",
            "100%|██████████| 582/582 [00:10<00:00, 56.09it/s]3, 28.28it/s, eval_loss=0.184, eval_MAE=0.737, eval_RMSE=0.928, best_eval_loss=0.184, train_loss=0.194, train_MAE=0.775, train_RMSE=0.995, steps=1104, best_checkpoint=1104]  \n",
            "100%|██████████| 582/582 [00:11<00:00, 52.53it/s]0, 27.86it/s, eval_loss=0.179, eval_MAE=0.715, eval_RMSE=0.965, best_eval_loss=0.179, train_loss=0.188, train_MAE=0.75, train_RMSE=0.962, steps=2208, best_checkpoint=2208]  \n",
            "100%|██████████| 582/582 [00:11<00:00, 51.61it/s]7, 24.19it/s, eval_loss=0.176, eval_MAE=0.703, eval_RMSE=0.923, best_eval_loss=0.176, train_loss=0.184, train_MAE=0.737, train_RMSE=0.947, steps=3312, best_checkpoint=3312]  \n",
            "100%|██████████| 582/582 [00:10<00:00, 53.78it/s]8, 29.13it/s, eval_loss=0.175, eval_MAE=0.699, eval_RMSE=0.946, best_eval_loss=0.175, train_loss=0.172, train_MAE=0.688, train_RMSE=0.894, steps=4416, best_checkpoint=4416]  \n",
            "100%|██████████| 582/582 [00:10<00:00, 53.83it/s]1, 31.15it/s, eval_loss=0.174, eval_MAE=0.694, eval_RMSE=0.897, best_eval_loss=0.174, train_loss=0.172, train_MAE=0.687, train_RMSE=0.893, steps=5520, best_checkpoint=5520]  \n",
            "100%|██████████| 582/582 [00:10<00:00, 55.81it/s]1, 26.99it/s, eval_loss=0.173, eval_MAE=0.69, eval_RMSE=0.903, best_eval_loss=0.173, train_loss=0.172, train_MAE=0.686, train_RMSE=0.893, steps=6624, best_checkpoint=6624]  \n",
            "100%|██████████| 582/582 [00:08<00:00, 67.40it/s]0, 27.93it/s, eval_loss=0.172, eval_MAE=0.69, eval_RMSE=0.943, best_eval_loss=0.172, train_loss=0.167, train_MAE=0.669, train_RMSE=0.876, steps=7728, best_checkpoint=7728]  \n",
            "100%|██████████| 582/582 [00:08<00:00, 71.73it/s]2, 34.53it/s, eval_loss=0.172, eval_MAE=0.687, eval_RMSE=0.919, best_eval_loss=0.172, train_loss=0.167, train_MAE=0.67, train_RMSE=0.876, steps=8832, best_checkpoint=8832]  \n",
            "100%|██████████| 582/582 [00:08<00:00, 69.28it/s]01, 36.73it/s, eval_loss=0.171, eval_MAE=0.685, eval_RMSE=0.911, best_eval_loss=0.171, train_loss=0.168, train_MAE=0.67, train_RMSE=0.879, steps=9936, best_checkpoint=9936] \n",
            "100%|██████████| 582/582 [00:09<00:00, 64.07it/s]03, 29.01it/s, eval_loss=0.171, eval_MAE=0.685, eval_RMSE=0.918, best_eval_loss=0.171, train_loss=0.163, train_MAE=0.653, train_RMSE=0.851, steps=11040, best_checkpoint=11040]  \n",
            "100%|██████████| 582/582 [00:09<00:00, 63.10it/s]56, 33.37it/s, eval_loss=0.171, eval_MAE=0.682, eval_RMSE=0.903, best_eval_loss=0.171, train_loss=0.165, train_MAE=0.658, train_RMSE=0.861, steps=12144, best_checkpoint=12144]  \n",
            "100%|██████████| 582/582 [00:09<00:00, 64.19it/s]13, 38.05it/s, eval_loss=0.17, eval_MAE=0.682, eval_RMSE=0.915, best_eval_loss=0.17, train_loss=0.165, train_MAE=0.66, train_RMSE=0.864, steps=13248, best_checkpoint=13248]   \n",
            "100%|██████████| 582/582 [00:08<00:00, 67.54it/s]44, 38.09it/s, eval_loss=0.171, eval_MAE=0.685, eval_RMSE=0.933, best_eval_loss=0.17, train_loss=0.161, train_MAE=0.646, train_RMSE=0.846, steps=14352, best_checkpoint=13248]  \n",
            "100%|██████████| 582/582 [00:08<00:00, 66.38it/s]09, 38.56it/s, eval_loss=0.171, eval_MAE=0.682, eval_RMSE=0.916, best_eval_loss=0.17, train_loss=0.162, train_MAE=0.649, train_RMSE=0.852, steps=15456, best_checkpoint=13248]  \n",
            "100%|██████████| 582/582 [00:08<00:00, 68.75it/s]41, 33.57it/s, eval_loss=0.17, eval_MAE=0.682, eval_RMSE=0.907, best_eval_loss=0.17, train_loss=0.163, train_MAE=0.651, train_RMSE=0.853, steps=16560, best_checkpoint=13248]  \n",
            "100%|██████████| 582/582 [00:07<00:00, 80.61it/s] 2, 49.13it/s, eval_loss=0.171, eval_MAE=0.684, eval_RMSE=0.936, best_eval_loss=0.17, train_loss=0.159, train_MAE=0.636, train_RMSE=0.834, steps=17664, best_checkpoint=13248]  \n",
            "100%|██████████| 582/582 [00:06<00:00, 93.62it/s] 6, 49.72it/s, eval_loss=0.17, eval_MAE=0.682, eval_RMSE=0.929, best_eval_loss=0.17, train_loss=0.16, train_MAE=0.639, train_RMSE=0.839, steps=18768, best_checkpoint=13248]  \n",
            "100%|██████████| 582/582 [00:06<00:00, 95.75it/s] 6, 49.36it/s, eval_loss=0.17, eval_MAE=0.68, eval_RMSE=0.921, best_eval_loss=0.17, train_loss=0.16, train_MAE=0.642, train_RMSE=0.842, steps=19872, best_checkpoint=19872]  \n",
            "100%|██████████| 582/582 [00:06<00:00, 92.73it/s]25, 41.72it/s, eval_loss=0.17, eval_MAE=0.681, eval_RMSE=0.924, best_eval_loss=0.17, train_loss=0.157, train_MAE=0.628, train_RMSE=0.821, steps=20976, best_checkpoint=19872]  \n",
            "100%|██████████| 582/582 [00:07<00:00, 82.85it/s] 8, 50.18it/s, eval_loss=0.17, eval_MAE=0.679, eval_RMSE=0.912, best_eval_loss=0.17, train_loss=0.158, train_MAE=0.632, train_RMSE=0.828, steps=22080, best_checkpoint=22080]  \n",
            "100%|██████████| 582/582 [00:07<00:00, 76.76it/s]20, 44.06it/s, eval_loss=0.169, eval_MAE=0.678, eval_RMSE=0.912, best_eval_loss=0.169, train_loss=0.159, train_MAE=0.635, train_RMSE=0.833, steps=23184, best_checkpoint=23184]  \n",
            "100%|██████████| 582/582 [00:06<00:00, 96.61it/s]45, 46.96it/s, eval_loss=0.171, eval_MAE=0.682, eval_RMSE=0.922, best_eval_loss=0.169, train_loss=0.154, train_MAE=0.617, train_RMSE=0.806, steps=24288, best_checkpoint=23184]  \n",
            "100%|██████████| 582/582 [00:06<00:00, 96.79it/s]17, 48.24it/s, eval_loss=0.17, eval_MAE=0.679, eval_RMSE=0.911, best_eval_loss=0.169, train_loss=0.156, train_MAE=0.624, train_RMSE=0.815, steps=25392, best_checkpoint=23184] \n",
            "100%|██████████| 582/582 [00:06<00:00, 96.14it/s]54, 48.56it/s, eval_loss=0.171, eval_MAE=0.683, eval_RMSE=0.935, best_eval_loss=0.169, train_loss=0.157, train_MAE=0.627, train_RMSE=0.821, steps=26496, best_checkpoint=23184]\n",
            "100%|██████████| 582/582 [00:06<00:00, 92.41it/s] 6, 45.94it/s, eval_loss=0.17, eval_MAE=0.681, eval_RMSE=0.928, best_eval_loss=0.169, train_loss=0.153, train_MAE=0.614, train_RMSE=0.804, steps=27600, best_checkpoint=23184] \n",
            "100%|██████████| 582/582 [00:05<00:00, 97.47it/s] 6, 50.38it/s, eval_loss=0.17, eval_MAE=0.681, eval_RMSE=0.937, best_eval_loss=0.169, train_loss=0.155, train_MAE=0.618, train_RMSE=0.81, steps=28704, best_checkpoint=23184] \n",
            "100%|██████████| 582/582 [00:06<00:00, 93.36it/s]50, 44.23it/s, eval_loss=0.17, eval_MAE=0.679, eval_RMSE=0.917, best_eval_loss=0.169, train_loss=0.155, train_MAE=0.62, train_RMSE=0.812, steps=29808, best_checkpoint=23184]\n",
            "100%|██████████| 582/582 [00:05<00:00, 97.00it/s] 2, 49.18it/s, eval_loss=0.17, eval_MAE=0.681, eval_RMSE=0.931, best_eval_loss=0.169, train_loss=0.152, train_MAE=0.609, train_RMSE=0.796, steps=30912, best_checkpoint=23184]\n",
            "100%|██████████| 582/582 [00:06<00:00, 93.72it/s]00, 43.80it/s, eval_loss=0.17, eval_MAE=0.679, eval_RMSE=0.919, best_eval_loss=0.169, train_loss=0.153, train_MAE=0.611, train_RMSE=0.797, steps=32016, best_checkpoint=23184]\n",
            "Training: 100%|██████████| 33140/33140 [19:26<00:00, 28.40it/s, eval_loss=0.17, eval_MAE=0.679, eval_RMSE=0.918, best_eval_loss=0.169, train_loss=0.153, train_MAE=0.614, train_RMSE=0.8, steps=33120, best_checkpoint=23184]  \n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "total_pbar = tqdm(total=len(train_loader)*config.epoches,\n",
        "                  desc=\"Training\", position=0, leave=True)\n",
        "\n",
        "metrics_list = []\n",
        "best_model_path= None\n",
        "for epoch in range(config.epoches):\n",
        "    # print(\"*\"*50 + f\"epoch: {epoch + 1}\" + \"*\"*50)\n",
        "\n",
        "    train_loss_list = []\n",
        "    prob_list = []\n",
        "    rating_list = []\n",
        "\n",
        "    for inputs in train_loader:\n",
        "        model = model.train()\n",
        "        optimizer.zero_grad()\n",
        "        probs = model(inputs)\n",
        "\n",
        "        rating = inputs['target_rating'].view(-1, 1)\n",
        "\n",
        "        loss = loss_func(probs, rating)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss_list.append(loss.item())\n",
        "\n",
        "        probs = probs.detach().cpu().numpy().flatten().tolist()\n",
        "        prob_list.extend(probs)\n",
        "        rating = rating.detach().cpu().flatten().tolist()\n",
        "        rating_list.extend(rating)\n",
        "\n",
        "        if (total_batch+1) % config.eval_steps == 0:\n",
        "\n",
        "            improve = False\n",
        "            model_metrics = evaluate(model, test_loader,min_max_scaler,loss_func)\n",
        "            eval_loss = model_metrics['eval_loss']\n",
        "\n",
        "            if eval_loss <= best_eval_loss:\n",
        "                improve = True\n",
        "                best_checkpoint = total_batch+1\n",
        "                best_eval_loss = eval_loss\n",
        "\n",
        "            train_loss = np.mean(train_loss_list)\n",
        "            \n",
        "            real_ratings =min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "            prediction_ratings=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]\n",
        "            MAE = metrics.mean_absolute_error(real_ratings,prediction_ratings)\n",
        "            RMSE = metrics.mean_squared_error(real_ratings,prediction_ratings)\n",
        "\n",
        "            model_metrics['best_eval_loss'] = best_eval_loss\n",
        "            model_metrics['train_loss'] = train_loss\n",
        "            model_metrics['train_MAE'] = MAE\n",
        "            model_metrics['train_RMSE'] = RMSE\n",
        "            \n",
        "            model_metrics[\"steps\"] = total_batch+1\n",
        "            model_metrics[\"best_checkpoint\"] = best_checkpoint\n",
        "            metrics_list.append(model_metrics)\n",
        "\n",
        "            if improve:\n",
        "                save_dir = os.path.join(\"models\", model_version)\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                model_path = save_model(model, save_dir, total_batch+1, model_metrics)\n",
        "                best_model_path = model_path\n",
        "            post_fix_message = {k:round(v,3) for k,v in model_metrics.items()}\n",
        "            total_pbar.set_postfix(post_fix_message)\n",
        "\n",
        "\n",
        "            model = model.train()\n",
        "\n",
        "        total_batch += 1\n",
        "        total_pbar.update(1)\n",
        "\n",
        "    model = model.train()\n",
        "\n",
        "total_pbar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "AzfHrJl6aP0t"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eval_loss</th>\n",
              "      <th>eval_MAE</th>\n",
              "      <th>eval_RMSE</th>\n",
              "      <th>best_eval_loss</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>train_MAE</th>\n",
              "      <th>train_RMSE</th>\n",
              "      <th>steps</th>\n",
              "      <th>best_checkpoint</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.184143</td>\n",
              "      <td>0.736572</td>\n",
              "      <td>0.928214</td>\n",
              "      <td>0.184143</td>\n",
              "      <td>0.193690</td>\n",
              "      <td>0.774760</td>\n",
              "      <td>0.994861</td>\n",
              "      <td>1104</td>\n",
              "      <td>1104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.178813</td>\n",
              "      <td>0.715165</td>\n",
              "      <td>0.964991</td>\n",
              "      <td>0.178813</td>\n",
              "      <td>0.187588</td>\n",
              "      <td>0.750352</td>\n",
              "      <td>0.961771</td>\n",
              "      <td>2208</td>\n",
              "      <td>2208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.175647</td>\n",
              "      <td>0.702612</td>\n",
              "      <td>0.922629</td>\n",
              "      <td>0.175647</td>\n",
              "      <td>0.184216</td>\n",
              "      <td>0.736864</td>\n",
              "      <td>0.947113</td>\n",
              "      <td>3312</td>\n",
              "      <td>3312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.174812</td>\n",
              "      <td>0.699243</td>\n",
              "      <td>0.946380</td>\n",
              "      <td>0.174812</td>\n",
              "      <td>0.171994</td>\n",
              "      <td>0.687977</td>\n",
              "      <td>0.893828</td>\n",
              "      <td>4416</td>\n",
              "      <td>4416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.693974</td>\n",
              "      <td>0.896908</td>\n",
              "      <td>0.173500</td>\n",
              "      <td>0.171867</td>\n",
              "      <td>0.687468</td>\n",
              "      <td>0.892833</td>\n",
              "      <td>5520</td>\n",
              "      <td>5520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.172624</td>\n",
              "      <td>0.690497</td>\n",
              "      <td>0.903026</td>\n",
              "      <td>0.172624</td>\n",
              "      <td>0.171615</td>\n",
              "      <td>0.686458</td>\n",
              "      <td>0.892932</td>\n",
              "      <td>6624</td>\n",
              "      <td>6624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.172498</td>\n",
              "      <td>0.690036</td>\n",
              "      <td>0.943347</td>\n",
              "      <td>0.172498</td>\n",
              "      <td>0.167136</td>\n",
              "      <td>0.668542</td>\n",
              "      <td>0.876448</td>\n",
              "      <td>7728</td>\n",
              "      <td>7728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.171659</td>\n",
              "      <td>0.686640</td>\n",
              "      <td>0.919350</td>\n",
              "      <td>0.171659</td>\n",
              "      <td>0.167386</td>\n",
              "      <td>0.669546</td>\n",
              "      <td>0.876080</td>\n",
              "      <td>8832</td>\n",
              "      <td>8832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.171352</td>\n",
              "      <td>0.685393</td>\n",
              "      <td>0.911475</td>\n",
              "      <td>0.171352</td>\n",
              "      <td>0.167615</td>\n",
              "      <td>0.670462</td>\n",
              "      <td>0.879389</td>\n",
              "      <td>9936</td>\n",
              "      <td>9936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.171122</td>\n",
              "      <td>0.684504</td>\n",
              "      <td>0.917753</td>\n",
              "      <td>0.171122</td>\n",
              "      <td>0.163206</td>\n",
              "      <td>0.652823</td>\n",
              "      <td>0.850921</td>\n",
              "      <td>11040</td>\n",
              "      <td>11040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.170519</td>\n",
              "      <td>0.682074</td>\n",
              "      <td>0.903362</td>\n",
              "      <td>0.170519</td>\n",
              "      <td>0.164501</td>\n",
              "      <td>0.658003</td>\n",
              "      <td>0.861265</td>\n",
              "      <td>12144</td>\n",
              "      <td>12144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.681756</td>\n",
              "      <td>0.915033</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.164902</td>\n",
              "      <td>0.659610</td>\n",
              "      <td>0.864185</td>\n",
              "      <td>13248</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.171333</td>\n",
              "      <td>0.685255</td>\n",
              "      <td>0.932987</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.161384</td>\n",
              "      <td>0.645534</td>\n",
              "      <td>0.846265</td>\n",
              "      <td>14352</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.170552</td>\n",
              "      <td>0.682179</td>\n",
              "      <td>0.916197</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.162358</td>\n",
              "      <td>0.649432</td>\n",
              "      <td>0.852000</td>\n",
              "      <td>15456</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.170494</td>\n",
              "      <td>0.681973</td>\n",
              "      <td>0.906783</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.162682</td>\n",
              "      <td>0.650726</td>\n",
              "      <td>0.853405</td>\n",
              "      <td>16560</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.171108</td>\n",
              "      <td>0.684447</td>\n",
              "      <td>0.935988</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.158939</td>\n",
              "      <td>0.635758</td>\n",
              "      <td>0.834231</td>\n",
              "      <td>17664</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.170463</td>\n",
              "      <td>0.681857</td>\n",
              "      <td>0.929267</td>\n",
              "      <td>0.170431</td>\n",
              "      <td>0.159730</td>\n",
              "      <td>0.638921</td>\n",
              "      <td>0.838705</td>\n",
              "      <td>18768</td>\n",
              "      <td>13248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.170109</td>\n",
              "      <td>0.680445</td>\n",
              "      <td>0.920612</td>\n",
              "      <td>0.170109</td>\n",
              "      <td>0.160408</td>\n",
              "      <td>0.641632</td>\n",
              "      <td>0.841948</td>\n",
              "      <td>19872</td>\n",
              "      <td>19872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.170277</td>\n",
              "      <td>0.681134</td>\n",
              "      <td>0.923997</td>\n",
              "      <td>0.170109</td>\n",
              "      <td>0.157098</td>\n",
              "      <td>0.628392</td>\n",
              "      <td>0.820920</td>\n",
              "      <td>20976</td>\n",
              "      <td>19872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.169703</td>\n",
              "      <td>0.678797</td>\n",
              "      <td>0.911592</td>\n",
              "      <td>0.169703</td>\n",
              "      <td>0.157998</td>\n",
              "      <td>0.631991</td>\n",
              "      <td>0.828167</td>\n",
              "      <td>22080</td>\n",
              "      <td>22080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.677727</td>\n",
              "      <td>0.912216</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.158712</td>\n",
              "      <td>0.634846</td>\n",
              "      <td>0.833246</td>\n",
              "      <td>23184</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.170535</td>\n",
              "      <td>0.682119</td>\n",
              "      <td>0.921828</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.154308</td>\n",
              "      <td>0.617232</td>\n",
              "      <td>0.806039</td>\n",
              "      <td>24288</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.169750</td>\n",
              "      <td>0.678981</td>\n",
              "      <td>0.910583</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.155988</td>\n",
              "      <td>0.623954</td>\n",
              "      <td>0.815144</td>\n",
              "      <td>25392</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.170769</td>\n",
              "      <td>0.683066</td>\n",
              "      <td>0.935331</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.156865</td>\n",
              "      <td>0.627461</td>\n",
              "      <td>0.821459</td>\n",
              "      <td>26496</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.170178</td>\n",
              "      <td>0.680692</td>\n",
              "      <td>0.928361</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.153432</td>\n",
              "      <td>0.613729</td>\n",
              "      <td>0.803858</td>\n",
              "      <td>27600</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.170304</td>\n",
              "      <td>0.681257</td>\n",
              "      <td>0.936875</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.154558</td>\n",
              "      <td>0.618231</td>\n",
              "      <td>0.810315</td>\n",
              "      <td>28704</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.169840</td>\n",
              "      <td>0.679367</td>\n",
              "      <td>0.916796</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.155076</td>\n",
              "      <td>0.620304</td>\n",
              "      <td>0.812109</td>\n",
              "      <td>29808</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.170365</td>\n",
              "      <td>0.681451</td>\n",
              "      <td>0.931394</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.152331</td>\n",
              "      <td>0.609325</td>\n",
              "      <td>0.796201</td>\n",
              "      <td>30912</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.169647</td>\n",
              "      <td>0.678618</td>\n",
              "      <td>0.918732</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.152720</td>\n",
              "      <td>0.610879</td>\n",
              "      <td>0.796648</td>\n",
              "      <td>32016</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.169658</td>\n",
              "      <td>0.678615</td>\n",
              "      <td>0.918409</td>\n",
              "      <td>0.169427</td>\n",
              "      <td>0.153394</td>\n",
              "      <td>0.613577</td>\n",
              "      <td>0.800086</td>\n",
              "      <td>33120</td>\n",
              "      <td>23184</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    eval_loss  eval_MAE  eval_RMSE  best_eval_loss  train_loss  train_MAE  \\\n",
              "0    0.184143  0.736572   0.928214        0.184143    0.193690   0.774760   \n",
              "1    0.178813  0.715165   0.964991        0.178813    0.187588   0.750352   \n",
              "2    0.175647  0.702612   0.922629        0.175647    0.184216   0.736864   \n",
              "3    0.174812  0.699243   0.946380        0.174812    0.171994   0.687977   \n",
              "4    0.173500  0.693974   0.896908        0.173500    0.171867   0.687468   \n",
              "5    0.172624  0.690497   0.903026        0.172624    0.171615   0.686458   \n",
              "6    0.172498  0.690036   0.943347        0.172498    0.167136   0.668542   \n",
              "7    0.171659  0.686640   0.919350        0.171659    0.167386   0.669546   \n",
              "8    0.171352  0.685393   0.911475        0.171352    0.167615   0.670462   \n",
              "9    0.171122  0.684504   0.917753        0.171122    0.163206   0.652823   \n",
              "10   0.170519  0.682074   0.903362        0.170519    0.164501   0.658003   \n",
              "11   0.170431  0.681756   0.915033        0.170431    0.164902   0.659610   \n",
              "12   0.171333  0.685255   0.932987        0.170431    0.161384   0.645534   \n",
              "13   0.170552  0.682179   0.916197        0.170431    0.162358   0.649432   \n",
              "14   0.170494  0.681973   0.906783        0.170431    0.162682   0.650726   \n",
              "15   0.171108  0.684447   0.935988        0.170431    0.158939   0.635758   \n",
              "16   0.170463  0.681857   0.929267        0.170431    0.159730   0.638921   \n",
              "17   0.170109  0.680445   0.920612        0.170109    0.160408   0.641632   \n",
              "18   0.170277  0.681134   0.923997        0.170109    0.157098   0.628392   \n",
              "19   0.169703  0.678797   0.911592        0.169703    0.157998   0.631991   \n",
              "20   0.169427  0.677727   0.912216        0.169427    0.158712   0.634846   \n",
              "21   0.170535  0.682119   0.921828        0.169427    0.154308   0.617232   \n",
              "22   0.169750  0.678981   0.910583        0.169427    0.155988   0.623954   \n",
              "23   0.170769  0.683066   0.935331        0.169427    0.156865   0.627461   \n",
              "24   0.170178  0.680692   0.928361        0.169427    0.153432   0.613729   \n",
              "25   0.170304  0.681257   0.936875        0.169427    0.154558   0.618231   \n",
              "26   0.169840  0.679367   0.916796        0.169427    0.155076   0.620304   \n",
              "27   0.170365  0.681451   0.931394        0.169427    0.152331   0.609325   \n",
              "28   0.169647  0.678618   0.918732        0.169427    0.152720   0.610879   \n",
              "29   0.169658  0.678615   0.918409        0.169427    0.153394   0.613577   \n",
              "\n",
              "    train_RMSE  steps  best_checkpoint  \n",
              "0     0.994861   1104             1104  \n",
              "1     0.961771   2208             2208  \n",
              "2     0.947113   3312             3312  \n",
              "3     0.893828   4416             4416  \n",
              "4     0.892833   5520             5520  \n",
              "5     0.892932   6624             6624  \n",
              "6     0.876448   7728             7728  \n",
              "7     0.876080   8832             8832  \n",
              "8     0.879389   9936             9936  \n",
              "9     0.850921  11040            11040  \n",
              "10    0.861265  12144            12144  \n",
              "11    0.864185  13248            13248  \n",
              "12    0.846265  14352            13248  \n",
              "13    0.852000  15456            13248  \n",
              "14    0.853405  16560            13248  \n",
              "15    0.834231  17664            13248  \n",
              "16    0.838705  18768            13248  \n",
              "17    0.841948  19872            19872  \n",
              "18    0.820920  20976            19872  \n",
              "19    0.828167  22080            22080  \n",
              "20    0.833246  23184            23184  \n",
              "21    0.806039  24288            23184  \n",
              "22    0.815144  25392            23184  \n",
              "23    0.821459  26496            23184  \n",
              "24    0.803858  27600            23184  \n",
              "25    0.810315  28704            23184  \n",
              "26    0.812109  29808            23184  \n",
              "27    0.796201  30912            23184  \n",
              "28    0.796648  32016            23184  \n",
              "29    0.800086  33120            23184  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_metrics = pd.DataFrame(metrics_list)\n",
        "df_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='steps'>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df_metrics = df_metrics.set_index(\"steps\")\n",
        "df_metrics[['eval_loss','train_loss']].plot() "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (7) Validate Best Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = BSTRecommender(config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BSTRecommender(\n",
              "  (embedding_layers): ModuleDict(\n",
              "    (user): Embedding(6041, 32)\n",
              "    (movie): Embedding(3884, 32)\n",
              "    (occupation): Embedding(22, 32)\n",
              "    (age_group): Embedding(8, 32)\n",
              "    (position): Embedding(4, 32)\n",
              "  )\n",
              "  (transformer_layer): TransformerLayer(\n",
              "    (transformer_blocks): ModuleList(\n",
              "      (0-2): 3 x TransformerBlock(\n",
              "        (multihead_attention): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Sequential(\n",
              "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "        (layer_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mlp): MLP(\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0): Linear(in_features=513, out_features=256, bias=True)\n",
              "      (1): LeakyReLU(negative_slope=0.01)\n",
              "      (2): Dropout(p=0.2, inplace=False)\n",
              "      (3): Linear(in_features=256, out_features=64, bias=True)\n",
              "      (4): LeakyReLU(negative_slope=0.01)\n",
              "      (5): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (fc): Linear(in_features=64, out_features=1, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model.load_state_dict(torch.load(best_model_path))\n",
        "best_model.eval()\n",
        "best_model.to(config.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 197/582 [00:02<00:04, 90.19it/s] "
          ]
        }
      ],
      "source": [
        "best_model.eval()\n",
        "prob_list= []\n",
        "rating_list = []\n",
        "eval_loss_list = []\n",
        "pbar = tqdm(total = len(test_loader),desc = \"\",position=0, leave=True)\n",
        "for inputs in test_loader:\n",
        "    with torch.no_grad():\n",
        "        probs = best_model(inputs)\n",
        "        ratings = inputs['target_rating'].view(-1,1)\n",
        "        \n",
        "        loss = loss_func(probs, ratings)\n",
        "        eval_loss_list.append(loss.item())\n",
        "\n",
        "        probs = probs.cpu().numpy().flatten().tolist()\n",
        "        prob_list.extend(probs)\n",
        "\n",
        "        ratings = ratings.cpu().numpy().flatten().tolist()\n",
        "        rating_list.extend(ratings)\n",
        "\n",
        "        pbar.update(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prediction = pd.DataFrame()\n",
        "prediction['real']=min_max_scaler.inverse_transform(np.array(rating_list).reshape(-1,1))[:,0]\n",
        "prediction['prediction']=min_max_scaler.inverse_transform(np.array(prob_list).reshape(-1,1))[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MAE = metrics.mean_absolute_error(prediction['real'],prediction['prediction'])\n",
        "RMSE = metrics.mean_squared_error(prediction['real'],prediction['prediction'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MAE:0.6791747625216363,RMSE:0.8993003489021135\n"
          ]
        }
      ],
      "source": [
        "print(f\"MAE:{MAE},RMSE:{RMSE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>73450</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.326733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49038</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.969398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>915</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.036180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25386</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.020055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55833</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.863297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65726</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.974751</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22096</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.009012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63292</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.890207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.587009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61549</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.994724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10683</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.848940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35427</th>\n",
              "      <td>4.0</td>\n",
              "      <td>4.027750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10782</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.038360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20508</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.018812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41841</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.999498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48948</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.058909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42335</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.958163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21802</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.802449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48088</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.984358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43104</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.451460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5972</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.747344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21564</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.402739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28424</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.951378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42028</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.974417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17682</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.042223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4.014594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56047</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.999336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48722</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.966421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44338</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.935953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41130</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.979130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7133</th>\n",
              "      <td>5.0</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49516</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.997284</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12834</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.978307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6750</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.966438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31975</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.160172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72580</th>\n",
              "      <td>2.0</td>\n",
              "      <td>1.514966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1202</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.999089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17452</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.995407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60144</th>\n",
              "      <td>3.0</td>\n",
              "      <td>4.999995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46395</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.004385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31733</th>\n",
              "      <td>5.0</td>\n",
              "      <td>4.525938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2672</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.948301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63798</th>\n",
              "      <td>4.0</td>\n",
              "      <td>2.996095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39871</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.974153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31140</th>\n",
              "      <td>4.0</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4261</th>\n",
              "      <td>2.0</td>\n",
              "      <td>2.996868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52430</th>\n",
              "      <td>4.0</td>\n",
              "      <td>3.985413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20643</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.962333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3907</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.795759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54265</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.341172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       real  prediction\n",
              "73450   1.0    1.326733\n",
              "49038   3.0    3.969398\n",
              "915     5.0    3.036180\n",
              "25386   5.0    4.020055\n",
              "55833   3.0    1.863297\n",
              "65726   5.0    3.974751\n",
              "22096   4.0    4.009012\n",
              "63292   5.0    3.890207\n",
              "73      1.0    2.587009\n",
              "61549   4.0    3.994724\n",
              "10683   3.0    3.848940\n",
              "35427   4.0    4.027750\n",
              "10782   5.0    4.038360\n",
              "20508   1.0    1.018812\n",
              "41841   5.0    4.999498\n",
              "48948   5.0    4.058909\n",
              "42335   4.0    3.958163\n",
              "21802   4.0    3.802449\n",
              "48088   4.0    3.984358\n",
              "43104   4.0    3.451460\n",
              "5972    4.0    2.747344\n",
              "21564   2.0    1.402739\n",
              "28424   3.0    3.951378\n",
              "42028   4.0    3.974417\n",
              "17682   3.0    4.042223\n",
              "1183    1.0    4.014594\n",
              "56047   3.0    2.999336\n",
              "48722   4.0    3.966421\n",
              "44338   3.0    3.935953\n",
              "41130   2.0    3.979130\n",
              "7133    5.0    5.000000\n",
              "49516   2.0    2.997284\n",
              "12834   4.0    3.978307\n",
              "6750    4.0    3.966438\n",
              "31975   3.0    3.160172\n",
              "72580   2.0    1.514966\n",
              "1202    3.0    2.999089\n",
              "17452   3.0    2.995407\n",
              "60144   3.0    4.999995\n",
              "46395   4.0    3.004385\n",
              "31733   5.0    4.525938\n",
              "2672    4.0    3.948301\n",
              "63798   4.0    2.996095\n",
              "39871   4.0    3.974153\n",
              "31140   4.0    5.000000\n",
              "4261    2.0    2.996868\n",
              "52430   4.0    3.985413\n",
              "20643   3.0    3.962333\n",
              "3907    1.0    1.795759\n",
              "54265   1.0    2.341172"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1164/1164 [00:25<00:00, 113.94it/s]"
          ]
        }
      ],
      "source": [
        "shuffle(prediction).iloc[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
